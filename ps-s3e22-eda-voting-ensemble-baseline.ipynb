{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\"> Introduction</p>","metadata":{}},{"cell_type":"code","source":"# Misc\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport os\nfrom copy import deepcopy\nfrom functools import partial\nimport gc\nimport warnings\n\n# Import sklearn classes for model selection, cross validation, and performance evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, KFold\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\nfrom category_encoders import OneHotEncoder, OrdinalEncoder, CountEncoder\nfrom imblearn.under_sampling import RandomUnderSampler\n\n# Import libraries for Hypertuning\nimport optuna\n\n# Import libraries for gradient boosting\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\nfrom imblearn.ensemble import BalancedRandomForestClassifier\nfrom sklearn.impute import KNNImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import NuSVC, SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegressionCV, LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom catboost import CatBoost, CatBoostRegressor, CatBoostClassifier\nfrom catboost import Pool","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-16T21:42:22.606459Z","iopub.execute_input":"2023-09-16T21:42:22.606867Z","iopub.status.idle":"2023-09-16T21:42:22.618708Z","shell.execute_reply.started":"2023-09-16T21:42:22.606825Z","shell.execute_reply":"2023-09-16T21:42:22.6175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seaborn\nrc = {\n    \"axes.facecolor\": \"#FAEEE9\",\n    \"figure.facecolor\": \"#FAEEE9\",\n    \"axes.edgecolor\": \"#000000\",\n    \"grid.color\": \"#EBEBE7\",\n    \"font.family\": \"arial\",\n    \"axes.labelcolor\": \"#000000\",\n    \"xtick.color\": \"#000000\",\n    \"ytick.color\": \"#000000\",\n    \"grid.alpha\": 0.4\n}\nsns.set(rc=rc)\n\n# Useful line of code to set the display option so we could see all the columns in pd dataframe\npd.set_option('display.max_columns', None)\n\n# Suppress warnings\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\n# Functions\ndef print_sl():\n    print(\"=\" * 50)\n    print()\n\ndef show_na(df, column):\n    sns.countplot(x='outcome', data=df[df[column].isnull()])\n    plt.show() ","metadata":{"execution":{"iopub.status.busy":"2023-09-16T17:16:02.739429Z","iopub.execute_input":"2023-09-16T17:16:02.739733Z","iopub.status.idle":"2023-09-16T17:16:02.748898Z","shell.execute_reply.started":"2023-09-16T17:16:02.739707Z","shell.execute_reply":"2023-09-16T17:16:02.747999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\"> Data Preprocessing</p>","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/playground-series-s3e22/train.csv')\ntest = pd.read_csv('/kaggle/input/playground-series-s3e22/test.csv')\nsample_submission = pd.read_csv('/kaggle/input/playground-series-s3e22/sample_submission.csv')\n\ntrain_orig = pd.read_csv('/kaggle/input/horse-survival-dataset/horse.csv')\n\ntrain.drop('id',axis=1,inplace=True)\ntest.drop('id',axis=1,inplace=True)\n\nprint('Data Loaded Succesfully!')\nprint_sl()\n\nprint(f'train shape: {train.shape}')\nprint(f'are there any null values in train: {train.isnull().any().any()}\\n')\n\nprint(f'test shape: {test.shape}')\nprint(f'are there any null values in test: {test.isnull().any().any()}\\n')\n\nprint(f'train_orig shape: {train_orig.shape}')\nprint(f'are there any null values in test: {train_orig.isnull().any().any()}\\n')\n\ncategorical_cols = ['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', 'mucous_membrane', 'capillary_refill_time',\n                   'pain', 'peristalsis', 'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', 'rectal_exam_feces',\n                   'abdomen', 'abdomo_appearance', 'surgical_lesion', 'cp_data']\n\nnum_cols = ['hospital_number', 'rectal_temp', 'pulse', 'respiratory_rate', 'nasogastric_reflux_ph', 'packed_cell_volume', 'total_protein',\n           'abdomo_protein', 'lesion_1', 'lesion_2', 'lesion_3']\n\ntarget = 'outcome'\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:34.331316Z","iopub.execute_input":"2023-09-16T22:42:34.331693Z","iopub.status.idle":"2023-09-16T22:42:34.402819Z","shell.execute_reply.started":"2023-09-16T22:42:34.331662Z","shell.execute_reply":"2023-09-16T22:42:34.401849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block alert-warning\">  \n    <b>ðŸ’¡ Info:</b> The dataset contains a significant number of NA values.\n</div>","metadata":{}},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">EDA</p>","metadata":{}},{"cell_type":"markdown","source":"### Target Distribution","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/kimtaehun/eda-and-baseline-with-multiple-models\ndef plot_count(df: pd.core.frame.DataFrame, col: str, title_name: str='Train') -> None:\n    # Set background color\n    \n    f, ax = plt.subplots(1, 2, figsize=(14, 7))\n    plt.subplots_adjust(wspace=0.2)\n\n    s1 = df[col].value_counts()\n    N = len(s1)\n\n    outer_sizes = s1\n    inner_sizes = s1/N\n\n    outer_colors = ['#9E3F00', '#eb5e00', '#ff781f']\n    inner_colors = ['#ff6905', '#ff8838', '#ffa66b']\n\n    ax[0].pie(\n        outer_sizes,colors=outer_colors, \n        labels=s1.index.tolist(), \n        startangle=90, frame=True, radius=1.3, \n        explode=([0.05]*(N-1) + [.3]),\n        wedgeprops={'linewidth' : 1, 'edgecolor' : 'white'}, \n        textprops={'fontsize': 12, 'weight': 'bold'}\n    )\n\n    textprops = {\n        'size': 13, \n        'weight': 'bold', \n        'color': 'white'\n    }\n\n    ax[0].pie(\n        inner_sizes, colors=inner_colors,\n        radius=1, startangle=90,\n        autopct='%1.f%%', explode=([.1]*(N-1) + [.3]),\n        pctdistance=0.8, textprops=textprops\n    )\n\n    center_circle = plt.Circle((0,0), .68, color='black', fc='white', linewidth=0)\n    ax[0].add_artist(center_circle)\n\n    x = s1\n    y = s1.index.tolist()\n    sns.barplot(\n        x=x, y=y, ax=ax[1],\n        palette='YlOrBr_r', orient='horizontal'\n    )\n\n    ax[1].spines['top'].set_visible(False)\n    ax[1].spines['right'].set_visible(False)\n    ax[1].tick_params(\n        axis='x',         \n        which='both',      \n        bottom=False,      \n        labelbottom=False\n    )\n\n    for i, v in enumerate(s1):\n        ax[1].text(v, i+0.1, str(v), color='black', fontweight='bold', fontsize=12)\n\n    plt.setp(ax[1].get_yticklabels(), fontweight=\"bold\")\n    plt.setp(ax[1].get_xticklabels(), fontweight=\"bold\")\n    ax[1].set_xlabel(col, fontweight=\"bold\", color='black')\n    ax[1].set_ylabel('count', fontweight=\"bold\", color='black')\n\n    f.suptitle(f'{title_name}', fontsize=18, fontweight='bold')\n    plt.tight_layout()\n    plt.show()\n\nplot_count(train, 'outcome', 'Target Variable(Outcome) Distribution')","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2023-09-16T17:16:02.871385Z","iopub.execute_input":"2023-09-16T17:16:02.871866Z","iopub.status.idle":"2023-09-16T17:16:03.462008Z","shell.execute_reply.started":"2023-09-16T17:16:02.871828Z","shell.execute_reply":"2023-09-16T17:16:03.461236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Categorical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(categorical_cols)*3))\n\nfor i, col in enumerate(categorical_cols):\n    \n    plt.subplot(len(categorical_cols)//2 + len(categorical_cols) % 2, 2, i+1)\n    sns.countplot(x=col, hue=\"outcome\", data=train, palette='YlOrRd')\n    plt.title(f\"{col} countplot by outcome\", fontweight = 'bold')\n    plt.ylim(0, train[col].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T17:16:17.958516Z","iopub.execute_input":"2023-09-16T17:16:17.958883Z","iopub.status.idle":"2023-09-16T17:16:23.352014Z","shell.execute_reply.started":"2023-09-16T17:16:17.958852Z","shell.execute_reply":"2023-09-16T17:16:23.350958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Numerical Variables","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, len(num_cols) * 3))\n\nfor i, col in enumerate(num_cols):\n    # Plotting for outcome\n    plt.subplot(len(num_cols), 2, i+1)\n    sns.histplot(x=col, hue=\"outcome\", data=train, bins=30, kde=True, palette='YlOrRd')\n    plt.title(f\"{col} distribution for outcome\", fontweight=\"bold\")\n    plt.ylim(0, train[col].value_counts().max() + 10)\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T17:16:23.354316Z","iopub.execute_input":"2023-09-16T17:16:23.354656Z","iopub.status.idle":"2023-09-16T17:16:30.792494Z","shell.execute_reply.started":"2023-09-16T17:16:23.354625Z","shell.execute_reply":"2023-09-16T17:16:30.791393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scatter Matrix","metadata":{}},{"cell_type":"code","source":"# https://www.kaggle.com/code/yaaangzhou/playground-s3-e22-eda-modeling/notebook\ndef plot_pair(df_train,num_var,target,plotname):\n    '''\n    Funtion to make a pairplot:\n    df_train: total data\n    num_var: a list of numeric variable\n    target: target variable\n    '''\n    g = sns.pairplot(data=df_train, x_vars=num_var, y_vars=num_var, hue=target, corner=True,  palette='YlOrRd')\n    g._legend.set_bbox_to_anchor((0.8, 0.7))\n    g._legend.set_title(target)\n    g._legend.loc = 'upper left'\n    g._legend.get_title().set_fontsize(14)\n    for item in g._legend.get_texts():\n        item.set_fontsize(14)\n\n    plt.suptitle(plotname, ha='center', fontweight='bold', fontsize=25, y=0.98)\n    plt.show()\n\nplot_pair(train, num_cols, target, plotname = 'Scatter Matrix with Target')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T17:16:30.794124Z","iopub.execute_input":"2023-09-16T17:16:30.794445Z","iopub.status.idle":"2023-09-16T17:17:04.143634Z","shell.execute_reply.started":"2023-09-16T17:16:30.794418Z","shell.execute_reply":"2023-09-16T17:17:04.142328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Correlation Heatmap","metadata":{}},{"cell_type":"code","source":"# Create a copy of the dataframe\ndf_encoded = train.copy()\n\n# Assuming these are your categorical variables, including 'outcome'\ncategorical_vars = ['surgery', 'age', 'temp_of_extremities', 'peripheral_pulse', \n                    'mucous_membrane', 'capillary_refill_time', 'pain', 'peristalsis', \n                    'abdominal_distention', 'nasogastric_tube', 'nasogastric_reflux', \n                    'rectal_exam_feces', 'abdomen', 'abdomo_appearance', 'surgical_lesion', \n                    'cp_data', 'outcome']\n\n# Label encode categorical columns\nlabel_encoders = {}\nfor column in categorical_vars:\n    le = LabelEncoder()\n    df_encoded[column] = le.fit_transform(train[column])\n    label_encoders[column] = le\n\ndef plot_correlation_heatmap(df: pd.core.frame.DataFrame, title_name: str = 'Train correlation') -> None:\n    excluded_columns = ['id']\n    columns_without_excluded = [col for col in df.columns if col not in excluded_columns]\n    corr = df[columns_without_excluded].corr()\n    \n    fig, axes = plt.subplots(figsize=(14, 10))\n    mask = np.zeros_like(corr)\n    mask[np.triu_indices_from(mask)] = True\n    sns.heatmap(corr, mask=mask, linewidths=.5, cmap='YlOrBr_r', annot=True, annot_kws={\"size\": 6})\n    plt.title(title_name)\n    plt.show()\n\n# Plot correlation heatmap for encoded dataframe\nplot_correlation_heatmap(df_encoded, 'Encoded Dataset Correlation')","metadata":{"execution":{"iopub.status.busy":"2023-09-16T17:17:04.146325Z","iopub.execute_input":"2023-09-16T17:17:04.147117Z","iopub.status.idle":"2023-09-16T17:17:06.01811Z","shell.execute_reply.started":"2023-09-16T17:17:04.147078Z","shell.execute_reply":"2023-09-16T17:17:06.017325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Data Cleaning</p>","metadata":{}},{"cell_type":"code","source":"def data_cleaning(df, num_cols=num_cols, training=True):\n\n#     df.peripheral_pulse.fillna('novalue', inplace=True)\n#     df.temp_of_extremities.fillna('cool', inplace=True)\n#     df.mucous_membrane.fillna('pale_pink', inplace=True)\n#     df.capillary_refill_time.fillna('more_3_sec', inplace=True)\n#     df.peristalsis.fillna('absent', inplace=True)\n#     df.abdominal_distention.fillna('none', inplace=True)\n#     df.nasogastric_tube.fillna('none', inplace=True)\n#     df.nasogastric_reflux.fillna('none', inplace=True)\n    \n#     # not sure\n#     df.rectal_exam_feces.fillna('absent', inplace=True)\n#     df.abdomen.fillna('normal', inplace=True) \n    \n#     if training:\n#         #df.loc[df.pain.isnull() & (df.outcome == 'euthanized')].pain.fillna('depressed', inplace=True)\n#         df.loc[(df.pain.isnull()) & (df.outcome == 'euthanized'), 'pain'] = 'depressed'\n#         df.pain.fillna('mild_pain', inplace=True)\n        \n#         # df.loc[df.abdomo_appearance.isnull() & (df.outcome == 'died')].abdomo_appearance.fillna('serosanguious', inplace=True)\n#         df.loc[df.abdomo_appearance.isnull() & (df.outcome == 'died'), 'abdomo_appearance'] = 'serosanguious'\n#         df.abdomo_appearance.fillna('cloudy', inplace=True)\n        \n#     else:\n#         df.pain.fillna('mild_pain', inplace=True)\n#         df.abdomo_appearance.fillna('cloudy', inplace=True)\n    \n    for col in num_cols:\n        df[col].fillna(0, inplace=True)\n        \n    df[\"pain\"] = df[\"pain\"].replace('slight', 'moderate')\n    df[\"peristalsis\"] = df[\"peristalsis\"].replace('distend_small', 'normal')\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].replace('serosanguious', 'absent')\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].replace('slight', 'none')\n        \n    df[\"temp_of_extremities\"] = df[\"temp_of_extremities\"].fillna(\"normal\").map({'cold': 0, 'cool': 1, 'normal': 2, 'warm': 3})\n    df[\"peripheral_pulse\"] = df[\"peripheral_pulse\"].fillna(\"normal\").map({'absent': 0, 'reduced': 1, 'normal': 2, 'increased': 3})\n    df[\"capillary_refill_time\"] = df[\"capillary_refill_time\"].fillna(\"3\").map({'less_3_sec': 0, '3': 1, 'more_3_sec': 2})\n    df[\"pain\"] = df[\"pain\"].fillna(\"depressed\").map({'alert': 0, 'depressed': 1, 'moderate': 2, 'mild_pain': 3, 'severe_pain': 4, 'extreme_pain': 5})\n    df[\"peristalsis\"] = df[\"peristalsis\"].fillna(\"hypomotile\").map({'hypermotile': 0, 'normal': 1, 'hypomotile': 2, 'absent': 3})\n    df[\"abdominal_distention\"] = df[\"abdominal_distention\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'moderate': 2, 'severe': 3})\n    df[\"nasogastric_tube\"] = df[\"nasogastric_tube\"].fillna(\"none\").map({'none': 0, 'slight': 1, 'significant': 2})\n    df[\"nasogastric_reflux\"] = df[\"nasogastric_reflux\"].fillna(\"none\").map({'less_1_liter': 0, 'none': 1, 'more_1_liter': 2})\n    df[\"rectal_exam_feces\"] = df[\"rectal_exam_feces\"].fillna(\"absent\").map({'absent': 0, 'decreased': 1, 'normal': 2, 'increased': 3})\n    df[\"abdomen\"] = df[\"abdomen\"].fillna(\"distend_small\").map({'normal': 0, 'other': 1, 'firm': 2,'distend_small': 3, 'distend_large': 4})\n    df[\"abdomo_appearance\"] = df[\"abdomo_appearance\"].fillna(\"serosanguious\").map({'clear': 0, 'cloudy': 1, 'serosanguious': 2})\n        \n    return df\n\ndef encode(df, categorical_vars):\n    label_encoders = {}\n    for col in categorical_vars:\n        le = LabelEncoder()\n        df[col] = le.fit_transform(df[col])\n        label_encoders[col] = le\n    return df\n\ndef features_engineering(df):\n    df['lesion_2'] = df['lesion_2'].apply(lambda x:1 if x>0 else 0)\n    data_preprocessed = df.copy()\n     \n    data_preprocessed[\"abs_rectal_temp\"] = (data_preprocessed[\"rectal_temp\"] - 37.8).abs()\n    data_preprocessed.drop(columns=[\"rectal_temp\"])\n    \n    return data_preprocessed","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:39.01774Z","iopub.execute_input":"2023-09-16T22:42:39.018385Z","iopub.status.idle":"2023-09-16T22:42:39.037235Z","shell.execute_reply.started":"2023-09-16T22:42:39.018351Z","shell.execute_reply":"2023-09-16T22:42:39.036185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = data_cleaning(train)\ntest = data_cleaning(test, training=False)\ntrain_orig = data_cleaning(train_orig)\n\ntrain = encode(train, categorical_cols)\ntest = encode(test, categorical_cols)\ntrain_orig = encode(train_orig, categorical_cols)\n\ntotal = pd.concat([train, train_orig], ignore_index=True)\ntotal.drop_duplicates(inplace=True)\ntotal.drop('lesion_3',axis=1,inplace=True)\ntotal = features_engineering(total)\ntest = features_engineering(test)\ntest.drop('lesion_3',axis=1,inplace=True)\n\nprint(f'train shape: {train.shape}')\nprint(f'are there any null values in train: {train.isnull().any().any()}\\n')\n\nprint(f'test shape: {test.shape}')\nprint(f'are there any null values in test: {test.isnull().any().any()}\\n')\n\nprint(f'total shape: {total.shape}')\nprint(f'are there any null values in test: {total.isnull().any().any()}\\n')\n\ntotal.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:47:48.549527Z","iopub.execute_input":"2023-09-16T22:47:48.549931Z","iopub.status.idle":"2023-09-16T22:47:48.595052Z","shell.execute_reply.started":"2023-09-16T22:47:48.549882Z","shell.execute_reply":"2023-09-16T22:47:48.59361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Model Building</p>","metadata":{}},{"cell_type":"code","source":"X_train = total.drop(columns=[target])\ny_train = total[target].map({'died':0,'euthanized':1,'lived':2})\nX_test = test\n\nprint(f'X_train shape: {X_train.shape}')\n\nprint(f'X_test shape: {X_test.shape}')\n\nprint(f'y_train shape: {y_train.shape}')\n\ndel train, test, total\ngc.collect();\n\nX_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:44.454077Z","iopub.execute_input":"2023-09-16T22:42:44.454466Z","iopub.status.idle":"2023-09-16T22:42:44.933536Z","shell.execute_reply.started":"2023-09-16T22:42:44.454433Z","shell.execute_reply":"2023-09-16T22:42:44.932556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Splitter:\n    def __init__(self, n_splits=5, test_size=0.2):\n        self.n_splits = n_splits\n        self.test_size = test_size\n\n    def split_data(self, X, y, random_state_list):\n        for random_state in random_state_list:\n            kf = KFold(n_splits=self.n_splits, random_state=random_state, shuffle=True)\n            for train_index, val_index in kf.split(X, y):\n                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n                y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n                yield X_train, X_val, y_train, y_val, val_index","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:45.91193Z","iopub.execute_input":"2023-09-16T22:42:45.912906Z","iopub.status.idle":"2023-09-16T22:42:45.919811Z","shell.execute_reply.started":"2023-09-16T22:42:45.912854Z","shell.execute_reply":"2023-09-16T22:42:45.918877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Classifier:\n    def __init__(self, n_estimators=100, device=\"cpu\", random_state=0):\n        self.n_estimators = n_estimators\n        self.device = device\n        self.random_state = random_state\n        self.models = self._define_model()\n        self.models_name = list(self._define_model().keys())\n        self.len_models = len(self.models)\n        \n    def _define_model(self):\n        \n        xgb_optuna1 = {\n            'n_estimators': 500,\n            'learning_rate': 0.14825592807938784,\n            'booster': 'gbtree',\n            'lambda': 8.286104243394034,\n            'alpha': 3.218706261523848,\n            'subsample': 0.9641392997798903,\n            'colsample_bytree': 0.6489144243365093,\n            'max_depth': 4, \n            'min_child_weight': 3,\n            'eta': 1.230361841253566,\n            'gamma': 0.007588382469327802, \n            'grow_policy': 'depthwise',\n            'random_state': self.random_state,\n        }\n\n        if self.device == 'gpu':\n            xgb_params['tree_method'] = 'gpu_hist'\n            xgb_params['predictor'] = 'gpu_predictor'\n        \n        lgb_optuna1 = {\n            'num_iterations': 200,\n            'learning_rate': 0.05087818591635374,\n            'max_depth': 10,\n            'lambda': 4.428505451747609,\n            'alpha': 4.34921696876783,\n            'subsample': 0.512929283477029,\n            'colsample_bytree': 0.5421760951211009, \n            'min_child_weight': 4,\n            'random_state': self.random_state,\n            'verbose': -1,\n        }\n      \n        cat_optuna1 = {\n            'iterations': 700,          \n            'learning_rate': 0.06806932341035855,\n            'depth': 3,\n            'l2_leaf_reg': 4.246994639881441,\n            'bagging_temperature': 0.08262764367292164,\n            'random_strength': 6.922710769000274, \n            'border_count': 88,\n            'random_state': self.random_state,\n            'verbose': False,\n        }\n      \n        hist_params = {\n            'l2_regularization': 0.01,\n            'early_stopping': True,\n            'learning_rate': 0.01,\n            'max_iter': self.n_estimators,\n            'max_depth': 4,\n            'max_bins': 255,\n            'min_samples_leaf': 10,\n            'max_leaf_nodes':10,\n            'class_weight':'balanced',\n            'random_state': self.random_state\n        }\n        models = {\n            'xgb01': xgb.XGBClassifier(**xgb_optuna1),\n            'lgb01': lgb.LGBMClassifier(**lgb_optuna1),\n            #'hgb': HistGradientBoostingClassifier(**hist_params),\n            'cat01': CatBoostClassifier(**cat_optuna1),\n        }\n        \n        return models","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:51.589427Z","iopub.execute_input":"2023-09-16T22:42:51.589998Z","iopub.status.idle":"2023-09-16T22:42:51.603639Z","shell.execute_reply.started":"2023-09-16T22:42:51.589967Z","shell.execute_reply":"2023-09-16T22:42:51.602751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\n# Config\nrandom_state = 42\nrandom_state_list =[42]\nn_estimators = 100\ndevice = 'cpu'\nn_splits=5\nearly_stopping_rounds = 500\nverbose = False\n\n\n# Split Data\nsplitter = Splitter(n_splits=n_splits)\nsplits = splitter.split_data(X_train, y_train, random_state_list=random_state_list)\n    \n# Initialize an array for storing test predictions\nclassifier = Classifier(n_estimators=n_estimators, device=device, random_state=random_state)\n\ntest_predss = np.zeros((X_test.shape[0]))\noof_predss = np.zeros((X_train.shape[0]))\nensemble_score = []\nweights = []\nmodels_name = [_ for _ in classifier.models_name if ('xgb' in _) or ('lgb' in _) or ('cat' in _)]\ntrained_models = dict(zip(models_name, [[] for _ in range(classifier.len_models)]))\nscore_dict = dict(zip(classifier.models_name, [[] for _ in range(len(classifier.models_name))]))\n\nfor i, (X_train_, X_val, y_train_, y_val, val_index) in enumerate(splits):\n    \n    n = i % n_splits\n    m = i // n_splits\n    \n\n    # Classifier models\n    classifier = Classifier(n_estimators, device, random_state)\n    models = classifier.models\n\n    # Store oof and test predictions for each base model\n    oof_preds = []\n    test_preds = []\n\n    # Loop over each base model and fit it\n    for name, model in models.items():\n        if ('xgb' in name) or ('lgb' in name) or ('cat' in name):\n            model.fit(X_train_, y_train_, eval_set=[(X_val, y_val)], early_stopping_rounds=early_stopping_rounds, verbose=verbose)\n            \n        else:\n            model.fit(X_train_, y_train_)\n            \n        if name in trained_models.keys():\n            trained_models[f'{name}'].append(deepcopy(model))\n\n        y_val_pred = model.predict(X_val)\n\n        score = f1_score(y_val, y_val_pred, average='micro')\n        score_dict[name].append(score)\n        print(f'{name} [FOLD-{n} SEED-{random_state_list[m]}] F1 score: {score:.5f}')\n        \n        oof_preds.append(y_val_pred)\n\n    ## Ensemble Model\n    model_tuples = [(key, value) for key, value in models.items()]\n    voting_classifier = VotingClassifier(estimators=model_tuples\n                                                    , voting='soft')\n    \n    voting_classifier.fit(X_train_, y_train_)\n    ensemble_pred = voting_classifier.predict(X_val)\n    ens_f1 = f1_score(y_val, ensemble_pred, average='micro')\n    \n    print('Fold', i+1, '==> Ensemble Model oof F1 score is ==>', ens_f1)\n    ensemble_score.append(ens_f1)\n    \n    # Predict to X_test by the best ensemble weights\n    print('Average F1 of Ensemble Model is:', np.mean(ensemble_score))\n    print_sl()\n\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:42:53.492284Z","iopub.execute_input":"2023-09-16T22:42:53.492639Z","iopub.status.idle":"2023-09-16T22:45:00.223487Z","shell.execute_reply.started":"2023-09-16T22:42:53.49261Z","shell.execute_reply":"2023-09-16T22:45:00.221554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <p style=\"font-family:JetBrains Mono; font-weight:bold; letter-spacing: 2px; color:#005B46; font-size:140%; text-align:left;padding: 0px; border-bottom: 3px solid #003300\">Predict and Submit</p>","metadata":{}},{"cell_type":"code","source":"voting_classifier.fit(X_train, y_train)\ntest_predss = voting_classifier.predict(X_test)\n\n# xgboost = models['xgb01'].fit(X_train, y_train)\n# test_predss = xgboost.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:19:00.138153Z","iopub.execute_input":"2023-09-16T22:19:00.138551Z","iopub.status.idle":"2023-09-16T22:19:06.497518Z","shell.execute_reply.started":"2023-09-16T22:19:00.138522Z","shell.execute_reply":"2023-09-16T22:19:06.496444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id': sample_submission['id'], 'outcome': test_predss})\nsubmission['outcome'] = submission['outcome'].map({0:'died',1:'euthanized',2:'lived'})\nsubmission.to_csv('submission.csv',index=False)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2023-09-16T22:19:06.499365Z","iopub.execute_input":"2023-09-16T22:19:06.499754Z","iopub.status.idle":"2023-09-16T22:19:06.517399Z","shell.execute_reply.started":"2023-09-16T22:19:06.499713Z","shell.execute_reply":"2023-09-16T22:19:06.516637Z"},"trusted":true},"execution_count":null,"outputs":[]}]}